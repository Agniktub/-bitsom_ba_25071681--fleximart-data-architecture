# Part 1: Database Design and ETL Pipeline Overview

This directory contains the implementation for Part 1 of the assignment, including the ETL pipeline to clean and load data into the relational database, schema documentation, business queries, and data quality report.

Key Files:
- etl_pipeline.py: ETL script for data processing and loading.
- schema_documentation.md: Documentation of the database schema.
- business_queries.sql: SQL queries for business questions.
- data_quality_report.txt: Report on data processing metrics (generated by ETL script).

To run:
1. Ensure MySQL database 'fleximart' is created and tables are set up using the provided schema (run the CREATE TABLE statements before ETL).
2. Place raw CSV files in D:/data/ (customers_raw.csv, products_raw.csv, sales_raw.csv).
3. Run python etl_pipeline.py (it will generate data_quality_report.txt).
4. After ETL, run business_queries.sql to test the queries.
